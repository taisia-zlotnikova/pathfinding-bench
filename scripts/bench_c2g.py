import os
import sys
import time
import argparse
import config
from map_parser import MapParser
import pathfinding_core as pfc
from gpu_planner import GPUPathPlanner
import torch

# –¶–≤–µ—Ç–∞ –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞
C_RESET  = "\033[0m"
C_BOLD   = "\033[1m"
C_GREEN  = "\033[32m"
C_YELLOW = "\033[33m"
C_CYAN   = "\033[36m"

def sync_gpu(device):
    """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –∑–∞–º–µ—Ä–∞ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ GPU"""
    if device.type == "cuda":
        torch.cuda.synchronize()
    elif device.type == "mps":
        torch.mps.synchronize()

def run_benchmarks(args):
    print(f"\n{C_BOLD}{C_CYAN}üöÄ –ó–∞–ø—É—Å–∫ –º–∞—Å—à—Ç–∞–±–Ω–æ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫–∞ Cost2Go (CPU vs GPU){C_RESET}")
    print(f"–†–∞–¥–∏—É—Å –æ–∫–Ω–∞: {args.radius} | –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {args.batch_size}")
    print(f"{'-'*85}")
    print(f"{'–ö–∞—Ä—Ç–∞':<25} | {'–ó–∞–¥–∞—á':<7} | {'CPU (—Å–µ–∫)':<12} | {'GPU (—Å–µ–∫)':<12} | {'–£—Å–∫–æ—Ä–µ–Ω–∏–µ':<10}")
    print(f"{'-'*85}")

    total_cpu_time = 0.0
    total_gpu_time = 0.0
    total_tasks = 0

    # –ü–µ—Ä–µ–±–æ—Ä —Ç–∏–ø–æ–≤ –∫–∞—Ä—Ç –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
    for map_type in config.MAP_TYPES:
        scen_dir = os.path.join(config.DATA_DIR, 'scen', map_type)
        map_dir = os.path.join(config.DATA_DIR, 'map', map_type)
        
        if not os.path.exists(scen_dir): continue

        scen_files = [f for f in os.listdir(scen_dir) if f.endswith('.scen')]
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞, –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ –∏–Ω–æ–µ
        for s_file in scen_files[:args.files_limit]:
            tasks = MapParser.parse_scenarios(os.path.join(scen_dir, s_file))
            if not tasks: continue
            
            map_name = tasks[0]["map_name"]
            if args.map and map_name != args.map: continue
                
            map_path = os.path.join(map_dir, map_name)
            if not os.path.exists(map_path): continue
            
            # –ß—Ç–µ–Ω–∏–µ –∫–∞—Ä—Ç—ã
            width, height, grid = MapParser.parse_map(map_path)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–æ–≤
            cpu_planner = pfc.PathPlanner(width, height, grid)
            gpu_planner = GPUPathPlanner(width, height, grid)
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–∫–µ—Ç–∞ –∑–∞–¥–∞—á
            batch_tasks = tasks[:args.batch_size]
            agents = [t["start"] for t in batch_tasks]
            goals = [t["goal"] for t in batch_tasks]
            B = len(agents)
            if B == 0: continue

            # --- –ü–†–û–ì–†–ï–í GPU ---
            # –ü–µ—Ä–≤—ã–π –≤—ã–∑–æ–≤ PyTorch —Ç—Ä–∞—Ç–∏—Ç –≤—Ä–µ–º—è –Ω–∞ –≤—ã–¥–µ–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏, –µ–≥–æ –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ–º
            gpu_planner.get_cost2go_windows_batch([agents[0]], [goals[0]], args.radius)
            sync_gpu(gpu_planner.device)

            # --- –ó–ê–ú–ï–† GPU (–ü–∞–∫–µ—Ç–Ω—ã–π –∑–∞–ø—É—Å–∫) ---
            t0 = time.perf_counter()
            gpu_planner.get_cost2go_windows_batch(agents, goals, args.radius)
            sync_gpu(gpu_planner.device)
            gpu_time = time.perf_counter() - t0

            # --- –ó–ê–ú–ï–† CPU (–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫) ---
            # –í C++ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è connectivity=4 –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å BFS PyTorch
            t0 = time.perf_counter()
            for i in range(B):
                cpu_planner.get_cost2go_window(agents[i][0], agents[i][1], goals[i][0], goals[i][1], args.radius, 4)
            cpu_time = time.perf_counter() - t0

            # --- –ü–û–î–°–ß–ï–¢ –ò –í–´–í–û–î ---
            speedup = cpu_time / gpu_time if gpu_time > 0 else 0
            color = C_GREEN if speedup > 1 else C_YELLOW
            
            print(f"{map_name[:25]:<25} | {B:<7} | {cpu_time:<12.4f} | {gpu_time:<12.4f} | {color}{speedup:.2f}x{C_RESET}")

            total_cpu_time += cpu_time
            total_gpu_time += gpu_time
            total_tasks += B

    print(f"{'-'*85}")
    if total_tasks > 0:
        avg_speedup = total_cpu_time / total_gpu_time
        print(f"{C_BOLD}–ò–¢–û–ì–û:{C_RESET} –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {total_tasks} –∑–∞–¥–∞—á.")
        print(f"–û–±—â–µ–µ –≤—Ä–µ–º—è CPU: {C_YELLOW}{total_cpu_time:.4f} —Å–µ–∫{C_RESET}")
        print(f"–û–±—â–µ–µ –≤—Ä–µ–º—è GPU: {C_GREEN}{total_gpu_time:.4f} —Å–µ–∫{C_RESET}")
        print(f"–°—Ä–µ–¥–Ω–µ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ: {C_BOLD}{C_CYAN}{avg_speedup:.2f}x{C_RESET}")
    else:
        print("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∑–∞–¥–∞—á –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Cost2Go Benchmark CPU vs GPU")
    parser.add_argument('--radius', type=int, default=10, help='–†–∞–¥–∏—É—Å –æ–∫–Ω–∞ –¥–ª—è cost2go')
    parser.add_argument('--batch_size', type=int, default=1024, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä –∞–≥–µ–Ω—Ç-—Ü–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (—Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞)')
    parser.add_argument('--files_limit', type=int, default=3, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤ –∫–∞–∂–¥–æ–π –ø–∞–ø–∫–µ')
    parser.add_argument('--map', type=str, default=None, help='–ó–∞–ø—É—Å–∫ —Ç–æ–ª—å–∫–æ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–∞—Ä—Ç—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)')
    
    args = parser.parse_args()
    run_benchmarks(args)